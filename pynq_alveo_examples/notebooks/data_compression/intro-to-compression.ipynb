{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xilinx Data Compression Library\n",
    "\n",
    "This notebook introduces some of the higher-level functions of the Xilinx [data compression library](https://github.com/Xilinx/Vitis_Libraries/tree/b658aa5cd262d080048526ce931d4570cb931a36/data_compression) which is part of the set of [Vitis Libraries](https://github.com/Xilinx/Vitis_Libraries). The bitstream delivered for this example is designed to showcase the core parts of the library in particular:\n",
    "\n",
    " * LZ4 compression and decompression\n",
    " * DEFLATE compression\n",
    "\n",
    "LZ4 is a block-based compression library optimized for speed and parallel access and DEFLATE is the compression format on which zlib and gzip are built. For this notebook we are going to focus on LZ4 as the compression library provides single accelerators for compression and decompression. DEFLATE is a more complex format and is split into three separate processes and is detailed in the *Zlib Acceleration* notebook alongside this one.\n",
    "\n",
    "First thing we need to do, as with any PYNQ program, is load the bitstream:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pynq\n",
    "\n",
    "ol = pynq.Overlay('compression.xclbin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which will allow us to inspect its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m            Overlay\n",
       "\u001b[0;31mString form:\u001b[0m     <pynq.overlay.Overlay object at 0x7fbc78e4fd90>\n",
       "\u001b[0;31mFile:\u001b[0m            /scratch/pynq-testing/ogden/conda/lib/python3.7/site-packages/pynq/overlay.py\n",
       "\u001b[0;31mDocstring:\u001b[0m      \n",
       "Default documentation for overlay compression.xclbin. The following\n",
       "attributes are available on this overlay:\n",
       "\n",
       "IP Blocks\n",
       "----------\n",
       "xilHuffmanKernel_1   : pynq.overlay.DefaultIP\n",
       "xilHuffmanKernel_2   : pynq.overlay.DefaultIP\n",
       "xilLz4Compress_1     : pynq.overlay.DefaultIP\n",
       "xilLz4Compress_2     : pynq.overlay.DefaultIP\n",
       "xilLz77Compress_1    : pynq.overlay.DefaultIP\n",
       "xilLz77Compress_2    : pynq.overlay.DefaultIP\n",
       "xilTreegenKernel_1   : pynq.overlay.DefaultIP\n",
       "xilTreegenKernel_2   : pynq.overlay.DefaultIP\n",
       "\n",
       "Hierarchies\n",
       "-----------\n",
       "None\n",
       "\n",
       "Interrupts\n",
       "----------\n",
       "None\n",
       "\n",
       "GPIO Outputs\n",
       "------------\n",
       "None\n",
       "\n",
       "Memories\n",
       "------------\n",
       "bank0                : Memory\n",
       "bank1                : Memory\n",
       "\u001b[0;31mClass docstring:\u001b[0m\n",
       "This class keeps track of a single bitstream's state and contents.\n",
       "\n",
       "The overlay class holds the state of the bitstream and enables run-time\n",
       "protection of bindlings.\n",
       "\n",
       "Our definition of overlay is: \"post-bitstream configurable design\".\n",
       "Hence, this class must expose configurability through content discovery\n",
       "and runtime protection.\n",
       "\n",
       "The overlay class exposes the IP and hierarchies as attributes in the\n",
       "overlay. If no other drivers are available the `DefaultIP` is constructed\n",
       "for IP cores at top level and `DefaultHierarchy` for any hierarchies that\n",
       "contain addressable IP. Custom drivers can be bound to IP and hierarchies\n",
       "by subclassing `DefaultIP` and `DefaultHierarchy`. See the help entries\n",
       "for those class for more details.\n",
       "\n",
       "This class stores four dictionaries: IP, GPIO, interrupt controller\n",
       "and interrupt pin dictionaries.\n",
       "\n",
       "Each entry of the IP dictionary is a mapping:\n",
       "'name' -> {phys_addr, addr_range, type, config, state}, where\n",
       "name (str) is the key of the entry.\n",
       "phys_addr (int) is the physical address of the IP.\n",
       "addr_range (int) is the address range of the IP.\n",
       "type (str) is the type of the IP.\n",
       "config (dict) is a dictionary of the configuration parameters.\n",
       "state (str) is the state information about the IP.\n",
       "\n",
       "Each entry of the GPIO dictionary is a mapping:\n",
       "'name' -> {pin, state}, where\n",
       "name (str) is the key of the entry.\n",
       "pin (int) is the user index of the GPIO, starting from 0.\n",
       "state (str) is the state information about the GPIO.\n",
       "\n",
       "Each entry in the interrupt controller dictionary is a mapping:\n",
       "'name' -> {parent, index}, where\n",
       "name (str) is the name of the interrupt controller.\n",
       "parent (str) is the name of the parent controller or '' if attached\n",
       "directly to the PS.\n",
       "index (int) is the index of the interrupt attached to.\n",
       "\n",
       "Each entry in the interrupt pin dictionary is a mapping:\n",
       "'name' -> {controller, index}, where\n",
       "name (str) is the name of the pin.\n",
       "controller (str) is the name of the interrupt controller.\n",
       "index (int) is the line index.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "bitfile_name : str\n",
       "    The absolute path of the bitstream.\n",
       "dtbo : str\n",
       "    The absolute path of the dtbo file for the full bitstream.\n",
       "ip_dict : dict\n",
       "    All the addressable IPs from PS. Key is the name of the IP; value is\n",
       "    a dictionary mapping the physical address, address range, IP type,\n",
       "    parameters, registers, and the state associated with that IP:\n",
       "    {str: {'phys_addr' : int, 'addr_range' : int,                'type' : str, 'parameters' : dict, 'registers': dict,                'state' : str}}.\n",
       "gpio_dict : dict\n",
       "    All the GPIO pins controlled by PS. Key is the name of the GPIO pin;\n",
       "    value is a dictionary mapping user index (starting from 0),\n",
       "    and the state associated with that GPIO pin:\n",
       "    {str: {'index' : int, 'state' : str}}.\n",
       "interrupt_controllers : dict\n",
       "    All AXI interrupt controllers in the system attached to\n",
       "    a PS interrupt line. Key is the name of the controller;\n",
       "    value is a dictionary mapping parent interrupt controller and the\n",
       "    line index of this interrupt:\n",
       "    {str: {'parent': str, 'index' : int}}.\n",
       "    The PS is the root of the hierarchy and is unnamed.\n",
       "interrupt_pins : dict\n",
       "    All pins in the design attached to an interrupt controller.\n",
       "    Key is the name of the pin; value is a dictionary\n",
       "    mapping the interrupt controller and the line index used:\n",
       "    {str: {'controller' : str, 'index' : int}}.\n",
       "pr_dict : dict\n",
       "    Dictionary mapping from the name of the partial-reconfigurable\n",
       "    hierarchical blocks to the loaded partial bitstreams:\n",
       "    {str: {'loaded': str, 'dtbo': str}}.\n",
       "device : pynq.Device\n",
       "    The device that the overlay is loaded on\n",
       "\u001b[0;31mInit docstring:\u001b[0m \n",
       "Return a new Overlay object.\n",
       "\n",
       "An overlay instantiates a bitstream object as a member initially.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "bitfile_name : str\n",
       "    The bitstream name or absolute path as a string.\n",
       "dtbo : str\n",
       "    The dtbo file name or absolute path as a string.\n",
       "download : bool\n",
       "    Whether the overlay should be downloaded.\n",
       "ignore_version : bool\n",
       "    Indicate whether or not to ignore the driver versions.\n",
       "device : pynq.Device\n",
       "    Device on which to load the Overlay. Defaults to\n",
       "    pynq.Device.active_device\n",
       "\n",
       "Note\n",
       "----\n",
       "This class requires a Vivado TCL file to be next to bitstream file\n",
       "with same name (e.g. `base.bit` and `base.tcl`).\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ol?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see there are multiple types of kernel with each type having two instances. For this notebook we are only interested in the `xilLz4Compress_1` kernel which we will use to introduce the concepts behind the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Signature (in_r: 'ap_uint<512> const *', out_r: 'ap_uint<512>*', compressd_size: 'unsigned int*', in_block_size: 'unsigned int*', block_size_in_kb: 'unsigned int', input_size: 'unsigned int')>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compress = ol.xilLz4Compress_1\n",
    "compress.signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before constructing the arguments to pass to accelerator we need to understand how the compression library is structured. The compress accelerator is composed of 8 separate internal pipelines with a splitter and combiner at each end:\n",
    "\n",
    "![compression pipeline](img/lzx_comp.png)\n",
    "\n",
    "With this logic we can start thinking of the formats for each argument:\n",
    "\n",
    " * `in_r` - the input data array consisting of 8 buffers of the block size arranged contiguously\n",
    " * `out_r` - the output data array consisting of 8 buffers of the block size arranged contiguously\n",
    " * `compressed_size` - an array of size 8 that will contain the sizes of the blocks after compression\n",
    " * `in_block_size` - an array of size 8 that contains the uncompressed sizes of the blocks (as the data may not fill the whole block)\n",
    " * `block_size_in_kb` - the block size\n",
    " * `input_size` - the total size of the input\n",
    " \n",
    "The LZ4 format has 4 possible block sizes from 64 KB to 4 MB. For this example we'll set the block size as 1 MB. Using this as a size we can create all of the buffers. Note that for this accelerator all of the arrays should be in `bank0` as we can see from the `mem` attribute of each entry in the `args` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_r': XrtArgument(name='in_r', index=1, type='ap_uint<512> const *', mem='bank0'),\n",
       " 'out_r': XrtArgument(name='out_r', index=2, type='ap_uint<512>*', mem='bank0'),\n",
       " 'compressd_size': XrtArgument(name='compressd_size', index=3, type='unsigned int*', mem='bank0'),\n",
       " 'in_block_size': XrtArgument(name='in_block_size', index=4, type='unsigned int*', mem='bank0'),\n",
       " 'block_size_in_kb': XrtArgument(name='block_size_in_kb', index=5, type='unsigned int', mem=None),\n",
       " 'input_size': XrtArgument(name='input_size', index=6, type='unsigned int', mem=None)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compress.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOCK_SIZE = 1024 * 1024\n",
    "\n",
    "in_buffers = pynq.allocate((8, BLOCK_SIZE), 'u1', target=ol.bank0)\n",
    "out_buffers = pynq.allocate((8, BLOCK_SIZE), 'u1', target=ol.bank0)\n",
    "compressed_size = pynq.allocate((8,), 'u4', target=ol.bank0)\n",
    "uncompressed_size = pynq.allocate((8,), 'u4', target=ol.bank0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a reasonably sized file to use as a test case. The test data we're using is the compression xclbin itself for the Xilinx u200 board. We can use numpy to reshape the array to make it more convenient. Note that we need to use a *memoryview* of the test data to avoid numpy trying to parse the data as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_data.bin', 'rb') as f:\n",
    "    test_data = f.read()\n",
    "\n",
    "in_buffers.reshape(8*BLOCK_SIZE)[:] = memoryview(test_data)[0:8*BLOCK_SIZE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The uncompressed size of each block is just 1 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncompressed_size[:] = BLOCK_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as a final step we need to sync the input buffers with the accelerator card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncompressed_size.sync_to_device()\n",
    "in_buffers.sync_to_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is now set up to call the accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "compress.call(in_buffers, out_buffers,\n",
    "             compressed_size, uncompressed_size,\n",
    "              1024, 8 * BLOCK_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the data back we first need to sync the buffer containing the sizes of the blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PynqBuffer([133515, 158756, 479440, 430620, 895308, 754169, 770095,\n",
       "            684801], dtype=uint32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_size.sync_from_device()\n",
    "compressed_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can now sync the output buffers - note that we only need to sync the part of the buffer that we know is filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    out_buffers[i,0:compressed_size[i]].sync_from_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify we have the correct result we want to pass the compressed data back through a software implementation. The `lz4` package provides a block-level API we can use for decompressing our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lz4.block\n",
    "\n",
    "decompressed_data = b''\n",
    "for i in range(8):\n",
    "    decompressed_data += lz4.block.decompress(out_buffers[i, 0:compressed_size[i]],\n",
    "                                              uncompressed_size=1024*1024)\n",
    "    \n",
    "decompressed_data == test_data[0:8*1024*1024]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea of the compression ratio we can concatenate the length of the compressed blocks and device by the 8 MB we started with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5133991241455078"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(compressed_size) / sum(uncompressed_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up\n",
    "\n",
    "You might want to *shutdown* this notebook at this point to ensure that all of the resources used are freed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (C) 2020 Xilinx, Inc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
