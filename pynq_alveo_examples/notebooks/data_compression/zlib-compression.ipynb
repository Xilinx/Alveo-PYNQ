{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressing using DEFLATE and zlib\n",
    "\n",
    "This notebook introduces the hardware functions for implementing DEFLATE - the compression format used by gzip and zlib. Using DEFLATE is more involved than the LZ4 algorithm introduced previously as it consists of three phases:\n",
    "\n",
    " 1. Duplicate sections of the data are replaced by references to create an LZ77 data stream\n",
    " 2. The frequency of characters and references are used to construct a huffman tree\n",
    " 3. The LZ77 data stream is bit-compressed using the huffman tree\n",
    "\n",
    "![deflate pipeline](img/deflate.png)\n",
    "\n",
    "In the data-compression library each of these phases is represented by a different kernel. We'll walk through each stage in turn looking at how they interact. Note that each kernel follows the structure outlined in the *Introduction to Compression* notebook - specifically that they operate on 8 blocks in parallel.\n",
    "\n",
    "First step to create our test data - for this example we are going to focus on a single  set of 8 1 MB blocks so we'll use the first 8 MB of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_data.bin', 'rb') as f:\n",
    "    test_data = f.read(8 * 1024 * 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can instantiate the xclbin file and get references to the kernels for each of the three stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pynq\n",
    "\n",
    "ol = pynq.Overlay('compression.xclbin')\n",
    "\n",
    "lz77 = ol.xilLz77Compress_1\n",
    "treegen = ol.xilTreegenKernel_1\n",
    "huffman = ol.xilHuffmanKernel_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LZ77 Compression\n",
    "\n",
    "Working from left to right in the above diagram we start with the LZ77 kernel and inspect the arguments to see what buffers we are going to need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_r': XrtArgument(name='in_r', index=1, type='ap_uint<512> const *', mem='bank0'),\n",
       " 'out_r': XrtArgument(name='out_r', index=2, type='ap_uint<512>*', mem='bank0'),\n",
       " 'compressd_size': XrtArgument(name='compressd_size', index=3, type='unsigned int*', mem='bank0'),\n",
       " 'in_block_size': XrtArgument(name='in_block_size', index=4, type='unsigned int*', mem='bank0'),\n",
       " 'dyn_ltree_freq': XrtArgument(name='dyn_ltree_freq', index=5, type='unsigned int*', mem='bank0'),\n",
       " 'dyn_dtree_freq': XrtArgument(name='dyn_dtree_freq', index=6, type='unsigned int*', mem='bank0'),\n",
       " 'block_size_in_kb': XrtArgument(name='block_size_in_kb', index=7, type='unsigned int', mem=None),\n",
       " 'input_size': XrtArgument(name='input_size', index=8, type='unsigned int', mem=None)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lz77.args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input and output buffers are the same as for LZ4 and we have already chosen a block size of 1 MB. Note that the LZ77 stream is 32-bit integers as each symbol can either be a literal byte or a reference consisting of a packed length and distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOCK_SIZE = 1024 * 1024\n",
    "\n",
    "in_buffers = pynq.allocate((8,BLOCK_SIZE), 'u1', target=ol.bank0)\n",
    "lz77_buffers = pynq.allocate((8, BLOCK_SIZE), 'u4', target=ol.bank0)\n",
    "\n",
    "uncompressed_size = pynq.allocate((8,), 'u4', target=ol.bank0)\n",
    "compressed_size = pynq.allocate((8,), 'u4', target=ol.bank0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The buffer sizes needed for the other arguments are less obvious and are defined by how the hardware was compiled. In our case we are using the defaults so we can extract a set of constants from the libraries [configuration file](\n",
    "https://github.com/Xilinx/Vitis_Libraries/blob/master/data_compression/L2/include/zlib_config.hpp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LTREE_SIZE = 1024\n",
    "DTREE_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the sizes of the literal/reference size tree and the distance tree. These sizes also define the size of the frequency arrays which are output from the LZ77 compressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltree_freq = pynq.allocate((8, LTREE_SIZE), 'u4', target=ol.bank0)\n",
    "dtree_freq = pynq.allocate((8, DTREE_SIZE), 'u4', target=ol.bank0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all of the buffers allocated we can copy the data to the card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_buffers.reshape(8*BLOCK_SIZE)[:] = memoryview(test_data)\n",
    "in_buffers.sync_to_device()\n",
    "\n",
    "uncompressed_size[:] = BLOCK_SIZE\n",
    "uncompressed_size.sync_to_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and perform the first stage of the compression pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lz77.call(in_buffers, lz77_buffers,\n",
    "          compressed_size, uncompressed_size,\n",
    "          ltree_freq, dtree_freq,\n",
    "          1024, 8*BLOCK_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a check to make sure that something sensible is happening we can have a look at the compressed sizes. Note that these sizes are in bytes and each symbol is now four bytes in length meaning that the number of symbols has been reduced even though their size has grown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PynqBuffer([ 212596,  318440, 1440364, 1303792, 3039656, 2491536, 2452716,\n",
       "            2136280], dtype=uint32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_size.sync_from_device()\n",
    "compressed_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the Huffman Tree\n",
    "\n",
    "Next we need to take the frequency data output by the LZ77 compressor and generate the huffman tree. We can again check the arguments of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dyn_ltree_freq': XrtArgument(name='dyn_ltree_freq', index=1, type='unsigned int*', mem='bank0'),\n",
       " 'dyn_dtree_freq': XrtArgument(name='dyn_dtree_freq', index=2, type='unsigned int*', mem='bank0'),\n",
       " 'dyn_bltree_freq': XrtArgument(name='dyn_bltree_freq', index=3, type='unsigned int*', mem='bank0'),\n",
       " 'dyn_ltree_codes': XrtArgument(name='dyn_ltree_codes', index=4, type='unsigned int*', mem='bank0'),\n",
       " 'dyn_dtree_codes': XrtArgument(name='dyn_dtree_codes', index=5, type='unsigned int*', mem='bank0'),\n",
       " 'dyn_bltree_codes': XrtArgument(name='dyn_bltree_codes', index=6, type='unsigned int*', mem='bank0'),\n",
       " 'dyn_ltree_blen': XrtArgument(name='dyn_ltree_blen', index=7, type='unsigned int*', mem='bank0'),\n",
       " 'dyn_dtree_blen': XrtArgument(name='dyn_dtree_blen', index=8, type='unsigned int*', mem='bank0'),\n",
       " 'dyn_bltree_blen': XrtArgument(name='dyn_bltree_blen', index=9, type='unsigned int*', mem='bank0'),\n",
       " 'max_codes': XrtArgument(name='max_codes', index=10, type='unsigned int*', mem='bank0'),\n",
       " 'block_size_in_kb': XrtArgument(name='block_size_in_kb', index=11, type='unsigned int', mem=None),\n",
       " 'input_size': XrtArgument(name='input_size', index=12, type='unsigned int', mem=None),\n",
       " 'blocks_per_chunk': XrtArgument(name='blocks_per_chunk', index=13, type='unsigned int', mem=None)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treegen.args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see three trees with frequency, code and bit-length arrays. We've already seen the literal tree and the distance tree and the third is a tree of bit-lengths used internally by the huffman coder. Returning to the config file above we can find its size and also the size for the `max_codes` array which again contains data useful to the internal operation of the coder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLTREE_SIZE = 64\n",
    "MAXCODE_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the information to allocate all of the arrays used by treegen kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bltree_freq = pynq.allocate((8, BLTREE_SIZE), 'u4', target=ol.bank0)\n",
    "\n",
    "ltree_codes = pynq.allocate((8, LTREE_SIZE), 'u4', target=ol.bank0)\n",
    "dtree_codes = pynq.allocate((8, DTREE_SIZE), 'u4', target=ol.bank0)\n",
    "bltree_codes = pynq.allocate((8, BLTREE_SIZE), 'u4', target=ol.bank0)\n",
    "\n",
    "ltree_blen = pynq.allocate((8, LTREE_SIZE), 'u4', target=ol.bank0)\n",
    "dtree_blen = pynq.allocate((8, DTREE_SIZE), 'u4', target=ol.bank0)\n",
    "bltree_blen = pynq.allocate((8, BLTREE_SIZE), 'u4', target=ol.bank0)\n",
    "\n",
    "max_codes = pynq.allocate((8, MAXCODE_SIZE), 'u4', target=ol.bank0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the new arrays are outputs of the tree generator and all of the input data is already on the card so we don't need to perform any syncing prior to calling the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "treegen.call(ltree_freq, dtree_freq, bltree_freq,\n",
    "             ltree_codes, dtree_codes, bltree_codes,\n",
    "             ltree_blen, dtree_blen, bltree_blen,\n",
    "             max_codes, 1024, 8 * BLOCK_SIZE, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huffman Coding\n",
    "\n",
    "The final stage is creating the huffman-coded data. Same as the previous kernels the first step is to look at the `args` dictionary to see what buffers we need and how to call the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_r': XrtArgument(name='in_r', index=1, type='ap_uint<512>*', mem='bank0'),\n",
       " 'out_r': XrtArgument(name='out_r', index=2, type='ap_uint<512>*', mem='bank0'),\n",
       " 'in_block_size': XrtArgument(name='in_block_size', index=3, type='unsigned int*', mem='bank0'),\n",
       " 'compressd_size': XrtArgument(name='compressd_size', index=4, type='unsigned int*', mem='bank0'),\n",
       " 'dyn_litmtree_codes': XrtArgument(name='dyn_litmtree_codes', index=5, type='unsigned int*', mem='bank0'),\n",
       " 'dyn_distree_codes': XrtArgument(name='dyn_distree_codes', index=6, type='unsigned int*', mem='bank0'),\n",
       " 'dyn_bitlentree_codes': XrtArgument(name='dyn_bitlentree_codes', index=7, type='unsigned int*', mem='bank0'),\n",
       " 'dyn_litmtree_blen': XrtArgument(name='dyn_litmtree_blen', index=8, type='unsigned int*', mem='bank0'),\n",
       " 'dyn_dtree_blen': XrtArgument(name='dyn_dtree_blen', index=9, type='unsigned int*', mem='bank0'),\n",
       " 'dyn_bitlentree_blen': XrtArgument(name='dyn_bitlentree_blen', index=10, type='unsigned int*', mem='bank0'),\n",
       " 'dyn_max_codes': XrtArgument(name='dyn_max_codes', index=11, type='unsigned int*', mem='bank0'),\n",
       " 'block_size_in_kb': XrtArgument(name='block_size_in_kb', index=12, type='unsigned int', mem=None),\n",
       " 'input_size': XrtArgument(name='input_size', index=13, type='unsigned int', mem=None)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huffman.args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only new buffer we need is the final output array. This is expected to be size of the original input array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_buffers = pynq.allocate((8,BLOCK_SIZE), 'u1', target=ol.bank0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coder can be called with the LZ77 buffer and the constructed tree to get the final compressed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "huffman.call(lz77_buffers, out_buffers,\n",
    "             compressed_size, uncompressed_size,\n",
    "             ltree_codes, dtree_codes, bltree_codes,\n",
    "             ltree_blen, dtree_blen, bltree_blen,\n",
    "             max_codes, 1024, 8*BLOCK_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `compressed_size` array has now been updated with the new sizes of the output block and we can check that to ensure that everything worked correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PynqBuffer([ 83335, 112135, 355840, 321234, 666936, 558682, 570153,\n",
       "            508385], dtype=uint32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_size.sync_from_device()\n",
    "compressed_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the ZLIB File\n",
    "\n",
    "We now have a set of DEFLATE encoded blocks but we need to package them up into a zlib data stream before we can decompress them with the built-in Python zlib library. A zlib file consists of:\n",
    "\n",
    " 1. A 2-byte header identifying the file type\n",
    " 2. A list of DEFLATE blocks ending with an empty block\n",
    " 3. An Adler-32 checksum of the uncompressed data\n",
    "\n",
    "The header and empty block are constants we can just define for this purpose and the `zlib` module provides a standalone `adler32` function we can use to calculate the checksum. More details of this structure can be found in [RFC1950](https://tools.ietf.org/html/rfc1950)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZLIB_HEADER = b'\\x78\\x9c'\n",
    "ZLIB_EMPTY_BLOCK = b'\\x01\\x00\\x00\\xff\\xff'\n",
    "\n",
    "import zlib\n",
    "import struct\n",
    "checksum = struct.pack('>I', zlib.adler32(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the LZ4 code shown in the previous notebooks we can use a `BytesIO` object to assemble the parts of the ZLIB stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "compressed_stream = io.BytesIO()\n",
    "compressed_stream.write(ZLIB_HEADER)\n",
    "\n",
    "for i in range(8):\n",
    "    size = compressed_size[i]\n",
    "    subbuf = out_buffers[i][0:size]\n",
    "    subbuf.sync_from_device()\n",
    "    compressed_stream.write(subbuf)\n",
    "    \n",
    "compressed_stream.write(ZLIB_EMPTY_BLOCK)\n",
    "compressed_stream.write(checksum)\n",
    "\n",
    "compressed_stream.seek(0)\n",
    "compressed = compressed_stream.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And use the `zlib.decompress` function to check our compressed data stream for validity ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncompressed = zlib.decompress(compressed)\n",
    "uncompressed == test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare the lengths of the compress and uncompressed streams to check the amount of compression. For the start of the bitstream we get about 2.6:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6406582153680334"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uncompressed) / len(compressed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which compares favorably with the default setting for software zlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.644351654365291"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uncompressed) / len(zlib.compress(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance\n",
    "\n",
    "To get a rough idea of the speed of the compressor we can run `%%timeit` on a cell containing all of the compute from the rest of the notebook. Note that this is a very crude measure as there is no overlapping of compute and communication or even compute of the three kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.7 ms ± 9.28 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "in_buffers.sync_to_device()\n",
    "uncompressed_size.sync_to_device()\n",
    "\n",
    "wh1 = lz77.start(in_buffers, lz77_buffers,\n",
    "                 compressed_size, uncompressed_size,\n",
    "                 ltree_freq, dtree_freq,\n",
    "                 1024, 8*BLOCK_SIZE)\n",
    "\n",
    "wh2 = treegen.start(ltree_freq, dtree_freq, bltree_freq,\n",
    "                    ltree_codes, dtree_codes, bltree_codes,\n",
    "                    ltree_blen, dtree_blen, bltree_blen,\n",
    "                    max_codes, 1024, 8 * BLOCK_SIZE, 8, waitfor=(wh1,))\n",
    "\n",
    "wh3 = huffman.start(lz77_buffers, out_buffers,\n",
    "                    compressed_size, uncompressed_size,\n",
    "                    ltree_codes, dtree_codes, bltree_codes,\n",
    "                    ltree_blen, dtree_blen, bltree_blen,\n",
    "                    max_codes, 1024, 8*BLOCK_SIZE, waitfor=(wh2,))\n",
    "\n",
    "zlib.adler32(test_data)\n",
    "wh3.wait()\n",
    "compressed_size.sync_from_device()\n",
    "\n",
    "compressed_stream = io.BytesIO()\n",
    "compressed_stream.write(ZLIB_HEADER)\n",
    "\n",
    "for i in range(8):\n",
    "    size = compressed_size[i]\n",
    "    subbuf = out_buffers[i][0:size]\n",
    "    subbuf.sync_from_device()\n",
    "    compressed_stream.write(subbuf)\n",
    "    \n",
    "compressed_stream.write(ZLIB_EMPTY_BLOCK)\n",
    "compressed_stream.write(checksum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even account for this we still get a reasonable speed-up over the built-in Python `zlib` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510 ms ± 103 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "zlib.compress(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more benchmarking and performance data see the [documentation of the data compression library](https://xilinx.github.io/Vitis_Libraries/data_compression/)\n",
    "\n",
    "### Cleaning up\n",
    "\n",
    "Remember to *shutdown* this notebook at this point to ensure that all of the resources used are freed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (C) 2020 Xilinx, Inc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
